## 问题：

> 总结限流，熔断，降级的常用方式，重试的注意事项，负载均衡的常用方式。

## 1. 隔离

> 隔离，本质上是对系统或资源进行分割，从而实现当系统发生故障时能限定传播范围和影响范围，既发生故障后只有出问题的服务不可用，保证其他服务让然可用

### 1.1 服务隔离

#### 1.1.1 动静分离，读写分离

- 动静隔离

  小到 CPU 的 cacheline false sharing、数据库 mysql 表设计中避免 bufferpool 频繁过期，隔离动静表，大到架构设计中的图片、静态资源等缓存加速。本质上都体现的一样的思路，即加速/缓存访问变换频次小的。比如 CDN 场景中，将静态资源和动态 API 分离，也是体现了隔离的思路

- 读写分离：

  主从、Replicaset、CQRS

#### 1.1.2 核心隔离

- 核心隔离：到将核心业务独立部署，非核心业务共享资源
- 热点隔离： remote cache 到 local cache
- 用户隔离：不同的用户可能有不同的级别，例如外部用户和管理员

#### 1.1.3 物理隔离

- 线程：常见的例子就是线程池，这个在 Golang 中一般不用过多考虑，runtime 已经帮我们管理好了
- 进程：我们现在一般使用容器化服务，跑在 k8s 上这就是一种进程级别的隔离
- 机房：我们目前在 K8s 的基础上做一些开发，常见的一种做法就是将我们的服务的不同副本尽量的分配在不同的可用区，实际上就是云厂商的不同机房，避免机房停电或者着火之类的影响
- 集群：非常重要的服务我们可以部署多套，在物理上进行隔离，常见的有异地部署，也可能就部署在同一个区域

## 2. 超时控制

> 超时控制，我们的组件能够快速失效（fail fast），因为我们不希望等到断开的实例直到超时。没有什么比挂起的请求和无响应的界面更令人失望。这不仅浪费资源，而且还会让用户体验变得更差。我们的服务是互相调用的，所以在这些延迟叠加前，应该特别注意防止那些超时的操作

超时控制时微服务可用性的第一道关，良好的超时策略可以尽可能让服务不堆积请求，尽快清空高延迟的请求，释放Goroutine

服务提供者定义好Latency SLO，更新到gRPC Proto 定义中，服务后续迭代，都应该保证SLO

- kit 基础库兜底默认超时，比如100ms，进行配置防御保护，避免出现类似60s之类的超大超时策略
- 配置中心公共模板，对于未配置的服务使用公共配置。

超时传递，当上游服务已经超时返回 504，但下游服务仍然在执行，会导致浪费资源做无用功。超时传递指的是把当前服务的剩余 Quota 传递到下游服务中，继承超时策略，控制请求级别的全局超时控制

- 进程内超时控制：一个请求在每个阶段(网络请求)开始前，就要检查是否还有足够的剩余来处理请求，以及继承他的超时策略，使用 Go 标准库的 context.WithTimeout。

在GRPC框架中，会依赖GRPC Metadata Exchange，基于HTTP2的Headers传递ggrpc-timeout字段，自动传递到下游，构建带timeout的context

- 双峰分布: 95%的请求耗时在100ms内，5%的请求可能永远不会完成（长超时）。
- 对于监控不要只看 mean，可以看看耗时分布统计，比如 95th，99th。
- 设置合理的超时，拒绝超长请求，或者当Server 不可用要主动失败。

